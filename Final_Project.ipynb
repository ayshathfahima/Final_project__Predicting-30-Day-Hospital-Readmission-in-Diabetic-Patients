{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e997ade5-7fa5-4f63-85b4-f471841bf37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (77599, 50)\n",
      "Final Shape after preprocessing: (77599, 2296)\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                6.0                      25.0                  1.0   \n",
      "1                1.0                       1.0                  7.0   \n",
      "2                1.0                       1.0                  7.0   \n",
      "3                1.0                       1.0                  7.0   \n",
      "4                1.0                       1.0                  7.0   \n",
      "\n",
      "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
      "0               1.0                41.0             0.0              1.0   \n",
      "1               3.0                59.0             0.0             18.0   \n",
      "2               2.0                11.0             5.0             13.0   \n",
      "3               2.0                44.0             1.0             16.0   \n",
      "4               1.0                51.0             0.0              8.0   \n",
      "\n",
      "   number_outpatient  number_emergency  number_inpatient  ...  insulin_No  \\\n",
      "0                0.0               0.0               0.0  ...        True   \n",
      "1                0.0               0.0               0.0  ...       False   \n",
      "2                2.0               0.0               1.0  ...        True   \n",
      "3                0.0               0.0               0.0  ...       False   \n",
      "4                0.0               0.0               0.0  ...       False   \n",
      "\n",
      "   insulin_Steady  insulin_Up  glyburide-metformin_No  \\\n",
      "0           False       False                    True   \n",
      "1           False        True                    True   \n",
      "2           False       False                    True   \n",
      "3           False        True                    True   \n",
      "4            True       False                    True   \n",
      "\n",
      "   glyburide-metformin_Steady  glyburide-metformin_Up  \\\n",
      "0                       False                   False   \n",
      "1                       False                   False   \n",
      "2                       False                   False   \n",
      "3                       False                   False   \n",
      "4                       False                   False   \n",
      "\n",
      "   glipizide-metformin_Steady  glimepiride-pioglitazone_Steady  change_No  \\\n",
      "0                       False                            False       True   \n",
      "1                       False                            False      False   \n",
      "2                       False                            False       True   \n",
      "3                       False                            False      False   \n",
      "4                       False                            False      False   \n",
      "\n",
      "   diabetesMed_Yes  \n",
      "0            False  \n",
      "1             True  \n",
      "2             True  \n",
      "3             True  \n",
      "4             True  \n",
      "\n",
      "[5 rows x 2296 columns]\n",
      "✅ Preprocessed dataset saved as 'preprocessed_diabetic_data.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"diabetic_data.csv\")\n",
    "print(\"Initial Shape:\", df.shape)\n",
    "\n",
    "\n",
    "#  Drop Unnecessary ID Columns\n",
    "\n",
    "df.drop(['encounter_id', 'patient_nbr'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Replace Missing Value Symbol '?' with NaN\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# Step 5: Encode Target Variable\n",
    "# '<30' = 1 (Readmitted within 30 days)\n",
    "# '>30' or 'NO' = 0\n",
    "\n",
    "df['readmitted'] = df['readmitted'].apply(lambda x: 1 if x == '<30' else 0)\n",
    "\n",
    "\n",
    "# Handle Missing Values\n",
    "# Drop columns with >50% missing values\n",
    "# Fill remaining NaN with Mode (most frequent value)\n",
    "\n",
    "df.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "\n",
    "# Encode Categorical Variables\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "#  Display Final Dataset Info\n",
    "\n",
    "print(\"Final Shape after preprocessing:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Save Preprocessed Data\n",
    "\n",
    "df.to_csv(\"preprocessed_diabetic_data.csv\", index=False)\n",
    "print(\"✅ Preprocessed dataset saved as 'preprocessed_diabetic_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd2f07ea-8a9e-4808-98b1-ba6ef33d76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (62079, 2295)\n",
      "Test shape: (15520, 2295)\n",
      "✅ Selected Top 11 Features\n",
      " Training Logistic Regression...\n",
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     13765\n",
      "           1       0.46      0.01      0.03      1755\n",
      "\n",
      "    accuracy                           0.89     15520\n",
      "   macro avg       0.67      0.51      0.48     15520\n",
      "weighted avg       0.84      0.89      0.84     15520\n",
      "\n",
      "--------------------------------------------------\n",
      " Training Decision Tree...\n",
      "Decision Tree Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     13765\n",
      "           1       0.15      0.18      0.16      1755\n",
      "\n",
      "    accuracy                           0.79     15520\n",
      "   macro avg       0.52      0.52      0.52     15520\n",
      "weighted avg       0.81      0.79      0.80     15520\n",
      "\n",
      "--------------------------------------------------\n",
      " Training Random Forest...\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     13765\n",
      "           1       0.30      0.02      0.04      1755\n",
      "\n",
      "    accuracy                           0.88     15520\n",
      "   macro avg       0.59      0.51      0.49     15520\n",
      "weighted avg       0.82      0.88      0.84     15520\n",
      "\n",
      "--------------------------------------------------\n",
      " Training Gradient Boosting...\n",
      "Gradient Boosting Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     13765\n",
      "           1       0.51      0.01      0.03      1755\n",
      "\n",
      "    accuracy                           0.89     15520\n",
      "   macro avg       0.70      0.51      0.48     15520\n",
      "weighted avg       0.85      0.89      0.84     15520\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Model Performance Summary:\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "1        Decision Tree  0.792268   0.149403  0.178348  0.162597\n",
      "2        Random Forest  0.883634   0.296000  0.021083  0.039362\n",
      "3    Gradient Boosting  0.886985   0.510638  0.013675  0.026637\n",
      "0  Logistic Regression  0.886662   0.461538  0.013675  0.026563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train-Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"readmitted\", axis=1)\n",
    "y = df[\"readmitted\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "# Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Keep numeric columns only\n",
    "X_train_num = X_train.select_dtypes(include=[np.number])\n",
    "X_test_num = X_test[X_train_num.columns]\n",
    "\n",
    "# Impute missing numeric values with median\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_train_imp = pd.DataFrame(imp.fit_transform(X_train_num), columns=X_train_num.columns, index=X_train_num.index)\n",
    "X_test_imp = pd.DataFrame(imp.transform(X_test_num), columns=X_train_num.columns, index=X_test.index)\n",
    "\n",
    "# Variance Threshold\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X_train_vt = pd.DataFrame(vt.fit_transform(X_train_imp), columns=X_train_imp.columns[vt.get_support()], index=X_train_imp.index)\n",
    "X_test_vt = pd.DataFrame(vt.transform(X_test_imp), columns=X_train_imp.columns[vt.get_support()], index=X_test_imp.index)\n",
    "\n",
    "# Select top K features\n",
    "K_TOP_FEATURES = 30\n",
    "k = min(K_TOP_FEATURES, X_train_vt.shape[1])\n",
    "skb = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "X_train_sel = pd.DataFrame(skb.fit_transform(X_train_vt, y_train),\n",
    "                           columns=X_train_vt.columns[skb.get_support()],\n",
    "                           index=X_train_vt.index)\n",
    "X_test_sel = pd.DataFrame(skb.transform(X_test_vt),\n",
    "                          columns=X_train_vt.columns[skb.get_support()],\n",
    "                          index=X_test_vt.index)\n",
    "\n",
    "print(f\"✅ Selected Top {k} Features\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\" Training {name}...\")\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    y_pred = model.predict(X_test_sel)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "    print(f\"{name} Results:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Results Summary\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False)\n",
    "print(\"\\n✅ Model Performance Summary:\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc7c7a-7151-4080-882b-f147a9b81c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92e525-ab8c-47f5-ba7f-f9849be16fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3532ed2-79ea-4f88-909d-9d1493d78c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ebf9d-6855-44b5-b6f2-d3294863d4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
